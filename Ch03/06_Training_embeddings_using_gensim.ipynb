{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_embeddings_using_gensim.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c-w-m/pnlp/blob/master/Ch03/06_Training_embeddings_using_gensim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WGPwjhbbwPT"
      },
      "source": [
        "# Chapter 3.6: Training Embeddings Using __Gensim__\n",
        "Word embeddings are an approach to representing text in NLP. In this notebook we will demonstrate how to train embeddings using Genism. [Gensim](https://radimrehurek.com/gensim/index.html) is an open source Python library for natural language processing, with a focus on topic modeling (explained in chapter 7)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:40.863650Z",
          "start_time": "2021-04-05T21:26:40.339123Z"
        },
        "id": "TBw9OCYcYQ_n"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:40.894143Z",
          "start_time": "2021-04-05T21:26:40.865114Z"
        },
        "id": "5qWptd54ZcfV"
      },
      "source": [
        "# define training data\n",
        "#Genism word2vec requires that a format of ‘list of lists’ be provided for training where every document contained in a list.\n",
        "#Every list contains lists of tokens of that document.\n",
        "corpus = [['dog','bites','man'], [\"man\", \"bites\" ,\"dog\"],[\"dog\",\"eats\",\"meat\"],[\"man\", \"eats\",\"food\"]]\n",
        "\n",
        "#Training the model\n",
        "model_cbow = Word2Vec(corpus, min_count=1,sg=0) #using CBOW Architecture for trainnig\n",
        "model_skipgram = Word2Vec(corpus, min_count=1,sg=1)#using skipGram Architecture for training "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QjSxefPl4mh"
      },
      "source": [
        "## Continuous Bag of Words (CBOW) \n",
        "In CBOW, the primary task is to build a language model that correctly predicts the center word given the context words in which the center word appears."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:56.724662Z",
          "start_time": "2021-04-05T21:26:56.712651Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyZY8ME4lUjd",
        "outputId": "a2027e39-4cf7-425a-849c-28ac6a43402a"
      },
      "source": [
        "#Summarize the loaded model\n",
        "print(model_cbow)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(model_cbow.wv.vocab)\n",
        "print(words)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(model_cbow['dog'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=6, size=100, alpha=0.025)\n",
            "['dog', 'bites', 'man', 'eats', 'meat', 'food']\n",
            "[ 1.5272563e-03  3.0823143e-03 -3.3804951e-03 -3.1428083e-03\n",
            "  2.2466332e-03  6.2112015e-04 -2.7811723e-03 -2.9659085e-03\n",
            " -1.3845018e-03 -1.0679704e-03 -1.6333798e-03 -2.6655751e-03\n",
            "  1.9629470e-03 -4.3159369e-03 -6.8872940e-04 -3.4440032e-03\n",
            "  3.2118661e-03 -2.7149902e-03 -3.0569120e-03  2.4059096e-03\n",
            " -1.6733137e-03  2.8828131e-03  3.4532668e-03  4.0449455e-04\n",
            " -3.6279229e-03  2.5212732e-03 -4.9624010e-03  7.0500733e-05\n",
            " -1.5966175e-03  3.2820425e-03 -1.3758682e-03 -3.7259256e-04\n",
            "  2.5749868e-03  3.1122605e-03 -4.9211895e-03  1.5680203e-03\n",
            "  4.3737190e-04  3.4999684e-03 -3.2759327e-03 -3.0293607e-03\n",
            " -3.7514111e-03 -3.6232336e-03 -2.1212299e-03 -4.1303020e-03\n",
            "  3.8243306e-03 -1.5868167e-03  1.5789388e-03  1.4703074e-03\n",
            " -4.7776653e-03 -4.7189468e-03 -4.3726638e-03 -4.6205176e-03\n",
            "  3.9527213e-04  6.0655829e-04  2.0725809e-03 -3.2809997e-04\n",
            "  2.9776883e-03 -4.4842032e-03 -4.9260687e-03 -8.0167019e-04\n",
            "  4.8034787e-03  3.9348225e-03 -3.3385381e-03 -4.6129194e-03\n",
            " -4.4286199e-04 -3.2209756e-03 -4.9462537e-03 -1.1090755e-03\n",
            " -1.4485823e-03 -2.1140019e-03  4.7371676e-03  4.2810410e-04\n",
            " -1.8601894e-03 -1.3147400e-03 -1.9108664e-03 -6.0944083e-05\n",
            "  1.2653782e-03 -1.2535286e-03  2.3072799e-04  5.3684431e-04\n",
            "  2.8938334e-04 -3.9567281e-03  3.6048729e-03 -5.2380585e-04\n",
            "  4.3457681e-03  1.8425303e-03  4.8671942e-03  1.1311399e-03\n",
            " -3.3871885e-03 -2.1066123e-03 -4.5514740e-03  1.8171183e-03\n",
            "  6.0247950e-04 -2.2489326e-03  2.6748460e-03  2.5193738e-03\n",
            " -3.1640637e-03 -9.5405895e-04 -7.7657576e-04 -4.8142209e-04]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:57.420196Z",
          "start_time": "2021-04-05T21:26:57.417193Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMuHv52GeuoR",
        "outputId": "69d0e78b-40d3-433b-92eb-ae8f67607cea"
      },
      "source": [
        "#Compute similarity \n",
        "print(\"Similarity between eats and bites:\",model_cbow.similarity('eats', 'bites'))\n",
        "print(\"Similarity between eats and man:\",model_cbow.similarity('eats', 'man'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity between eats and bites: 0.10500215\n",
            "Similarity between eats and man: -0.10587834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twhTZfPOezTU"
      },
      "source": [
        "From the above similarity scores we can conclude that eats is more similar to bites than man."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:59.635831Z",
          "start_time": "2021-04-05T21:26:59.621818Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lv0V7WofmsB",
        "outputId": "f0fcb947-21f2-41f1-88c0-3c42f4321aa6"
      },
      "source": [
        "#Most similarity\n",
        "model_cbow.most_similar('meat')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bites', 0.22404563426971436),\n",
              " ('eats', 0.10473474860191345),\n",
              " ('dog', 0.10331213474273682),\n",
              " ('man', 0.0980159193277359),\n",
              " ('food', -0.1473582684993744)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:59.855822Z",
          "start_time": "2021-04-05T21:26:59.841810Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA783nrSalgs",
        "outputId": "2da893ce-cbae-4f3a-c7b2-74d9499fe4c3"
      },
      "source": [
        "# save model\n",
        "model_cbow.save('model_cbow.bin')\n",
        "\n",
        "# load model\n",
        "new_model_cbow = Word2Vec.load('model_cbow.bin')\n",
        "print(new_model_cbow)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=6, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deReLSI7mQyr"
      },
      "source": [
        "## SkipGram\n",
        "In skipgram, the task is to predict the context words from the center word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:27:00.517046Z",
          "start_time": "2021-04-05T21:27:00.508038Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QtUtsLglvY0",
        "outputId": "ecf0abd6-e49f-48e2-b56b-ace489c8d06f"
      },
      "source": [
        "#Summarize the loaded model\n",
        "print(model_skipgram)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(model_skipgram.wv.vocab)\n",
        "print(words)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(model_skipgram['dog'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=6, size=100, alpha=0.025)\n",
            "['dog', 'bites', 'man', 'eats', 'meat', 'food']\n",
            "[ 1.5272563e-03  3.0823143e-03 -3.3804951e-03 -3.1428083e-03\n",
            "  2.2466332e-03  6.2112015e-04 -2.7811723e-03 -2.9659085e-03\n",
            " -1.3845018e-03 -1.0679704e-03 -1.6333798e-03 -2.6655751e-03\n",
            "  1.9629470e-03 -4.3159369e-03 -6.8872940e-04 -3.4440032e-03\n",
            "  3.2118661e-03 -2.7149902e-03 -3.0569120e-03  2.4059096e-03\n",
            " -1.6733137e-03  2.8828131e-03  3.4532668e-03  4.0449455e-04\n",
            " -3.6279229e-03  2.5212732e-03 -4.9624010e-03  7.0500733e-05\n",
            " -1.5966175e-03  3.2820425e-03 -1.3758682e-03 -3.7259256e-04\n",
            "  2.5749868e-03  3.1122605e-03 -4.9211895e-03  1.5680203e-03\n",
            "  4.3737190e-04  3.4999684e-03 -3.2759327e-03 -3.0293607e-03\n",
            " -3.7514111e-03 -3.6232336e-03 -2.1212299e-03 -4.1303020e-03\n",
            "  3.8243306e-03 -1.5868167e-03  1.5789388e-03  1.4703074e-03\n",
            " -4.7776653e-03 -4.7189468e-03 -4.3726638e-03 -4.6205176e-03\n",
            "  3.9527213e-04  6.0655829e-04  2.0725809e-03 -3.2809997e-04\n",
            "  2.9776883e-03 -4.4842032e-03 -4.9260687e-03 -8.0167019e-04\n",
            "  4.8034787e-03  3.9348225e-03 -3.3385381e-03 -4.6129194e-03\n",
            " -4.4286199e-04 -3.2209756e-03 -4.9462537e-03 -1.1090755e-03\n",
            " -1.4485823e-03 -2.1140019e-03  4.7371676e-03  4.2810410e-04\n",
            " -1.8601894e-03 -1.3147400e-03 -1.9108664e-03 -6.0944083e-05\n",
            "  1.2653782e-03 -1.2535286e-03  2.3072799e-04  5.3684431e-04\n",
            "  2.8938334e-04 -3.9567281e-03  3.6048729e-03 -5.2380585e-04\n",
            "  4.3457681e-03  1.8425303e-03  4.8671942e-03  1.1311399e-03\n",
            " -3.3871885e-03 -2.1066123e-03 -4.5514740e-03  1.8171183e-03\n",
            "  6.0247950e-04 -2.2489326e-03  2.6748460e-03  2.5193738e-03\n",
            " -3.1640637e-03 -9.5405895e-04 -7.7657576e-04 -4.8142209e-04]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:27:02.660747Z",
          "start_time": "2021-04-05T21:27:02.642866Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YUsblEOfFWf",
        "outputId": "aa71eb25-a84c-4ff4-ce50-0ca8c8e4a838"
      },
      "source": [
        "#Compute similarity \n",
        "print(\"Similarity between eats and bites:\",model_skipgram.similarity('eats', 'bites'))\n",
        "print(\"Similarity between eats and man:\",model_skipgram.similarity('eats', 'man'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity between eats and bites: 0.10498691\n",
            "Similarity between eats and man: -0.10588615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdXVDePKnBpv"
      },
      "source": [
        "From the above similarity scores we can conclude that eats is more similar to bites than man."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:27:03.419546Z",
          "start_time": "2021-04-05T21:27:03.414541Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpF4qtwpmuM3",
        "outputId": "83ad18cf-2b9e-461a-ff01-7495c31ae168"
      },
      "source": [
        "#Most similarity\n",
        "model_skipgram.most_similar('meat')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bites', 0.22404563426971436),\n",
              " ('eats', 0.10466405749320984),\n",
              " ('dog', 0.10331211984157562),\n",
              " ('man', 0.09801590442657471),\n",
              " ('food', -0.14735828340053558)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:27:03.973454Z",
          "start_time": "2021-04-05T21:27:03.950433Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNDCEXRTnAnj",
        "outputId": "343cf6d9-f1a1-4ca0-985f-708d5b141a1e"
      },
      "source": [
        "# save model\n",
        "model_skipgram.save('model_skipgram.bin')\n",
        "\n",
        "# load model\n",
        "new_model_skipgram = Word2Vec.load('model_skipgram.bin')\n",
        "print(model_skipgram)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=6, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0MiqJ_1M0mX"
      },
      "source": [
        "## Training Your Embedding on Wiki Corpus\n",
        "\n",
        "##### The corpus download page : https://dumps.wikimedia.org/enwiki/20200120/\n",
        "The entire wiki corpus as of 28/04/2020 is just over 16GB in size.\n",
        "We will take a part of this corpus due to computation constraints and train our word2vec and fasttext embeddings.\n",
        "\n",
        "The file size is 294MB so it can take a while to download.\n",
        "\n",
        "Source for code which downloads files from Google Drive: https://stackoverflow.com/questions/25010369/wget-curl-large-file-from-google-drive/39225039#39225039"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:27:58.596845Z",
          "start_time": "2021-04-05T21:27:58.585833Z"
        },
        "id": "K6tzcAVwxFLX",
        "outputId": "45216c4d-af1c-4c6c-d134-7349a10006f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "os.makedirs('data/en', exist_ok= True)\n",
        "file_name = \"data/en/enwiki-latest-pages-articles-multistream14.xml-p13159683p14324602.bz2\"\n",
        "file_id = \"11804g0GcWnBIVDahjo5fQyc05nQLXGwF\"\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "if not os.path.exists(file_name):\n",
        "    download_file_from_google_drive(file_id, file_name)\n",
        "else:\n",
        "    print(\"file already exists, skipping download\")\n",
        "\n",
        "print(f\"File at: {file_name}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File at: data/en/enwiki-latest-pages-articles-multistream14.xml-p13159683p14324602.bz2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T08:59:17.024306Z",
          "start_time": "2021-04-03T08:59:17.022304Z"
        },
        "id": "wX1kx96JLYvt"
      },
      "source": [
        "from gensim.corpora.wikicorpus import WikiCorpus\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.fasttext import FastText\n",
        "import time"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T09:56:14.722195Z",
          "start_time": "2021-04-03T09:56:14.705177Z"
        },
        "id": "rJgsEUmRPppc"
      },
      "source": [
        "#Preparing the Training data\n",
        "wiki = WikiCorpus(file_name, lemmatize=False, dictionary={})\n",
        "sentences = list(wiki.get_texts())\n",
        "\n",
        "#if you get a memory error executing the lines above\n",
        "#comment the lines out and uncomment the lines below. \n",
        "#loading will be slower, but stable.\n",
        "# wiki = WikiCorpus(file_name, processes=4, lemmatize=False, dictionary={})\n",
        "# sentences = list(wiki.get_texts())\n",
        "\n",
        "#if you still get a memory error, try settings processes to 1 or 2 and then run it again."
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsIrgt_gPQda"
      },
      "source": [
        "### Hyperparameters\n",
        "\n",
        "\n",
        "1.   sg - Selecting the training algorithm: 1 for skip-gram else its 0 for CBOW. Default is CBOW.\n",
        "2.   min_count-  Ignores all words with total frequency lower than this.<br>\n",
        "There are many more hyperparamaeters whose list can be found in the official documentation [here.](https://radimrehurek.com/gensim/models/word2vec.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:01:20.065332Z",
          "start_time": "2021-04-03T09:59:12.350872Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idmfbr_8LvoN",
        "outputId": "b96412e5-d4aa-40ae-99a9-68d2fcdfa1e9"
      },
      "source": [
        "#CBOW\n",
        "start = time.time()\n",
        "word2vec_cbow = Word2Vec(sentences,min_count=10, sg=0)\n",
        "end = time.time()\n",
        "\n",
        "print(\"CBOW Model Training Complete.\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CBOW Model Training Complete.\n",
            "Time taken for training is:0.07 hrs \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:02:10.613551Z",
          "start_time": "2021-04-03T10:02:10.585535Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMdGn08-RkhM",
        "outputId": "dc845b9e-944b-4bec-8776-cf1c17c77364"
      },
      "source": [
        "#Summarize the loaded model\n",
        "print(word2vec_cbow)\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(word2vec_cbow.wv.vocab)\n",
        "print(f\"Length of vocabulary: {len(words)}\")\n",
        "print(\"Printing the first 30 words.\")\n",
        "print(words[:30])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(f\"Length of vector: {len(word2vec_cbow['film'])}\")\n",
        "print(word2vec_cbow['film'])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Compute similarity \n",
        "print(\"Similarity between film and drama:\",word2vec_cbow.similarity('film', 'drama'))\n",
        "print(\"Similarity between film and tiger:\",word2vec_cbow.similarity('film', 'tiger'))\n",
        "print(\"-\"*30)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=111150, size=100, alpha=0.025)\n",
            "------------------------------\n",
            "Length of vocabulary: 111150\n",
            "Printing the first 30 words.\n",
            "['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n",
            "------------------------------\n",
            "Length of vector: 100\n",
            "[-1.0506552  -0.02559625 -3.23259     1.488893    1.3472427  -0.71339667\n",
            " -1.3500955  -1.8422508   0.9123795  -0.33282     1.306864    1.256017\n",
            " -3.9414885  -3.2811587   0.92902136 -1.3302459   2.5690322  -4.466726\n",
            "  0.31229255 -1.1977108  -3.6023428   1.7325197   0.60706854  0.6550589\n",
            "  3.5523074   1.1816992  -1.67011     2.964605    3.1188414   0.46984217\n",
            "  0.59819984 -1.4899861  -0.784721   -0.51103383  0.10948575 -1.6183871\n",
            " -1.2906426  -0.7345948  -0.692857    1.6596159   3.453691   -3.9252017\n",
            "  2.4272904   2.8858774   0.33730602 -3.4826193   2.1415124   2.5323675\n",
            " -0.42801332  2.3852987   0.12433911 -0.22827327 -0.6018304  -1.3039285\n",
            "  1.0201906  -0.5670663   1.85096     2.1519625   1.283652    1.5573615\n",
            "  0.5524268   0.2689597  -1.6734223   3.2647762  -2.8402014  -0.1052008\n",
            "  3.376169   -0.6025841   0.42836937 -1.5431446   0.2882835   1.5294629\n",
            "  0.97362804  2.9559195   0.4641361   2.5233793   1.0349606  -2.9041884\n",
            " -0.49643442  3.7730134  -0.8856311  -4.207834    1.2960984   1.6572156\n",
            " -2.0053248   0.2906823  -0.48006558 -2.1316302  -2.4070039  -2.3456354\n",
            "  0.16006091  1.4782412  -1.4716297  -2.0326533  -0.40877232 -1.0830883\n",
            " -0.8839514   0.13750587 -0.6499561  -0.6167483 ]\n",
            "------------------------------\n",
            "Similarity between film and drama: 0.49067998\n",
            "Similarity between film and tiger: 0.1824794\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:02:16.109851Z",
          "start_time": "2021-04-03T10:02:15.257052Z"
        },
        "id": "rXrDOrKskcHX"
      },
      "source": [
        "# save model\n",
        "from gensim.models import Word2Vec, KeyedVectors   \n",
        "word2vec_cbow.wv.save_word2vec_format('word2vec_cbow.bin', binary=True)\n",
        "\n",
        "# load model\n",
        "# new_modelword2vec_cbow = Word2Vec.load('word2vec_cbow.bin')\n",
        "# print(word2vec_cbow)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:08:27.736688Z",
          "start_time": "2021-04-03T10:02:19.197708Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX0U0CbQOK30",
        "outputId": "a1ec70c0-c745-4e4f-a7e1-1d760c4c2667"
      },
      "source": [
        "#SkipGram\n",
        "start = time.time()\n",
        "word2vec_skipgram = Word2Vec(sentences,min_count=10, sg=1)\n",
        "end = time.time()\n",
        "\n",
        "print(\"SkipGram Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SkipGram Model Training Complete\n",
            "Time taken for training is:0.23 hrs \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:09:06.406929Z",
          "start_time": "2021-04-03T10:09:06.383908Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXnY9YInSvnI",
        "outputId": "15e9f607-53ac-44c6-d38c-17c83fce8d6f"
      },
      "source": [
        "#Summarize the loaded model\n",
        "print(word2vec_skipgram)\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(word2vec_skipgram.wv.vocab)\n",
        "print(f\"Length of vocabulary: {len(words)}\")\n",
        "print(\"Printing the first 30 words.\")\n",
        "print(words[:30])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(f\"Length of vector: {len(word2vec_skipgram['film'])}\")\n",
        "print(word2vec_skipgram['film'])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Compute similarity \n",
        "print(\"Similarity between film and drama:\",word2vec_skipgram.similarity('film', 'drama'))\n",
        "print(\"Similarity between film and tiger:\",word2vec_skipgram.similarity('film', 'tiger'))\n",
        "print(\"-\"*30)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=111150, size=100, alpha=0.025)\n",
            "------------------------------\n",
            "Length of vocabulary: 111150\n",
            "Printing the first 30 words.\n",
            "['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n",
            "------------------------------\n",
            "Length of vector: 100\n",
            "[-0.40480924  0.19233392 -0.38905182  0.37828633  0.23791173 -0.69260263\n",
            " -0.07492838 -0.310254    0.3276737   0.21507213  0.2542622  -0.18547595\n",
            " -0.2083325  -0.365353    0.03026555 -0.64667964 -0.39256847 -0.95628494\n",
            " -0.3719754  -0.17749608  0.22393923  0.13561735 -0.02995735  0.36526108\n",
            "  0.22936612  0.3042692  -0.21229504  0.3387915   0.48752365 -0.40663773\n",
            " -0.2855313  -0.15150711  0.24762839  0.16370678 -0.04403246  0.21982297\n",
            "  0.55844146 -0.02884511 -0.00423493  0.40492105  0.725358   -0.3371495\n",
            "  0.31590566 -0.1334996   0.33223957 -0.07637323 -0.17134221  0.02813141\n",
            " -0.31317097  0.01606399  0.23657532 -0.2821919   0.27416918 -0.31518817\n",
            "  0.00294008  0.30010656  0.3997657   0.5290835   0.3665893   0.5368277\n",
            "  0.54532576  0.40102515 -0.01756139  0.58948237 -0.32526848  0.37121946\n",
            "  0.19310117 -0.07726194 -0.28954208  0.12425181  0.06272643 -0.06545855\n",
            " -0.62200284  0.41471013  0.41518232  0.23703799  0.41643715 -0.04786891\n",
            " -0.31557667 -0.26231968  0.46511066 -0.38680172  0.3149275   0.05330396\n",
            " -0.049152    0.42629412 -0.10386752  0.17308083  0.4377178   0.08352167\n",
            " -0.15842831  0.34589496 -0.44530693  0.09154802  0.41266426 -0.19237489\n",
            " -0.5295199  -0.27956533  0.4812092  -0.46073243]\n",
            "------------------------------\n",
            "Similarity between film and drama: 0.6267486\n",
            "Similarity between film and tiger: 0.2569149\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:09:09.947695Z",
          "start_time": "2021-04-03T10:09:09.076901Z"
        },
        "id": "o8U7bfPSVB04"
      },
      "source": [
        "# save model\n",
        "word2vec_cbow.wv.save_word2vec_format('word2vec_sg.bin', binary=True)\n",
        "\n",
        "# load model\n",
        "# new_model_skipgram = Word2Vec.load('model_skipgram.bin')\n",
        "# print(model_skipgram)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kExlA8kfrKml"
      },
      "source": [
        "## FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:16:31.271764Z",
          "start_time": "2021-04-03T10:09:16.592670Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPd2VhMEk8gL",
        "outputId": "5265935e-ea93-4c21-fa59-727e580263f9"
      },
      "source": [
        "#CBOW\n",
        "start = time.time()\n",
        "fasttext_cbow = FastText(sentences, sg=0, min_count=10)\n",
        "end = time.time()\n",
        "\n",
        "print(\"FastText CBOW Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FastText CBOW Model Training Complete\n",
            "Time taken for training is:0.23 hrs \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:16:31.287283Z",
          "start_time": "2021-04-03T10:16:31.273765Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlQFl8-Zsost",
        "outputId": "f35a0ea7-2416-48f9-bf47-e62b9cd037da"
      },
      "source": [
        "#Summarize the loaded model\n",
        "print(fasttext_cbow)\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(fasttext_cbow.wv.vocab)\n",
        "print(f\"Length of vocabulary: {len(words)}\")\n",
        "print(\"Printing the first 30 words.\")\n",
        "print(words[:30])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(f\"Length of vector: {len(fasttext_cbow['film'])}\")\n",
        "print(fasttext_cbow['film'])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Compute similarity \n",
        "print(\"Similarity between film and drama:\",fasttext_cbow.similarity('film', 'drama'))\n",
        "print(\"Similarity between film and tiger:\",fasttext_cbow.similarity('film', 'tiger'))\n",
        "print(\"-\"*30)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FastText(vocab=111150, size=100, alpha=0.025)\n",
            "------------------------------\n",
            "Length of vocabulary: 111150\n",
            "Printing the first 30 words.\n",
            "['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n",
            "------------------------------\n",
            "Length of vector: 100\n",
            "[-3.1095068  -0.97738403 -0.4148361   2.1723313  -0.3926139  -2.9532897\n",
            "  0.78257734  3.0079002  -0.04771179  6.0281415   3.063762   -8.705526\n",
            "  0.34551618 -2.4340384   0.34824482 -2.81405     2.542777   -1.3970212\n",
            "  5.048003   -1.101865   -3.5768595  -0.7213247  -1.4273902   0.29522827\n",
            "  2.6626627  -1.0342059  -2.8289397  -3.7968981  -5.5886517  -1.1344062\n",
            " -0.89612794  0.22751266  2.4569476   0.54126287  1.3069663  -1.5429406\n",
            " -1.8660321   4.109258   -3.1627958  -1.6807796   2.527449    1.1229966\n",
            " -5.530825   -0.85293293 -2.5087993  -2.6210973   5.648731   -3.7121508\n",
            "  2.6129186   3.8297372   3.643708   -8.788062   -4.225693    1.3782752\n",
            " -0.25482833  0.5570492  -2.02599     1.237866   -6.640335   -1.4112973\n",
            "  2.6344693   0.21882965 -2.396605    3.6439056   1.1480123  -4.581508\n",
            "  3.311502    0.9231684  -0.7619714   2.3596323   0.9177279  -3.3162565\n",
            "  2.2162828   1.9840614  -2.3652804  -1.1841896  -2.0889194   1.4904879\n",
            "  3.0567694   4.4295306   2.2442818  -1.4969418  -4.6082196   2.3367877\n",
            "  1.7035378  -2.6323004  -0.57003254 -2.6967795   0.45302886 -4.0462327\n",
            " -0.9517359   3.2218332  -0.23836918  1.1521558   3.2888083  -1.6375585\n",
            " -0.44036415 -0.13663453  0.23389377 -0.87266123]\n",
            "------------------------------\n",
            "Similarity between film and drama: 0.5270887\n",
            "Similarity between film and tiger: 0.23979016\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:28:28.771383Z",
          "start_time": "2021-04-03T10:16:31.289284Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgSOxsNklAvh",
        "outputId": "814da779-60d0-40fd-e7ee-0f15c7496eb7"
      },
      "source": [
        "#SkipGram\n",
        "start = time.time()\n",
        "fasttext_skipgram = FastText(sentences, sg=1, min_count=10)\n",
        "end = time.time()\n",
        "\n",
        "print(\"FastText SkipGram Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FastText SkipGram Model Training Complete\n",
            "Time taken for training is:0.37 hrs \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:28:28.803412Z",
          "start_time": "2021-04-03T10:28:28.773386Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFiTAP0PsQwi",
        "outputId": "f863c464-9fde-4fbe-86bc-68c81b1387ad"
      },
      "source": [
        "#Summarize the loaded model\n",
        "print(fasttext_skipgram)\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(fasttext_skipgram.wv.vocab)\n",
        "print(f\"Length of vocabulary: {len(words)}\")\n",
        "print(\"Printing the first 30 words.\")\n",
        "print(words[:30])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(f\"Length of vector: {len(fasttext_skipgram['film'])}\")\n",
        "print(fasttext_skipgram['film'])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Compute similarity \n",
        "print(\"Similarity between film and drama:\",fasttext_skipgram.similarity('film', 'drama'))\n",
        "print(\"Similarity between film and tiger:\",fasttext_skipgram.similarity('film', 'tiger'))\n",
        "print(\"-\"*30)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FastText(vocab=111150, size=100, alpha=0.025)\n",
            "------------------------------\n",
            "Length of vocabulary: 111150\n",
            "Printing the first 30 words.\n",
            "['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n",
            "------------------------------\n",
            "Length of vector: 100\n",
            "[-0.33846703  0.5514187   0.23116641  0.27032182 -0.38991967 -0.03107124\n",
            " -0.0388683   0.20263244  0.00909805  0.23460355 -0.49365014 -0.6210484\n",
            "  0.13146438 -0.21467814 -0.28132766  0.17498098  0.24386536  0.25516975\n",
            "  0.00322998  0.21797052 -0.30652273 -0.2812657  -0.19846335 -0.02550178\n",
            "  0.42202958  0.04961881 -0.5410628   0.23720703 -0.11622997  0.36257976\n",
            "  0.066438    0.51200646 -0.05544357 -0.43429697  0.1863742  -0.46424323\n",
            " -0.25711092 -0.47104245 -0.35568997  0.22489314  0.10952259 -0.5474739\n",
            " -0.11191456  0.26798293 -0.37286508 -0.11697951 -0.12097134  0.19453503\n",
            "  0.11001916  0.60850954 -0.1795907   0.02242186 -0.07473661  0.34914917\n",
            " -0.27916357  0.23331262 -0.14669375 -0.06279243 -0.5620237  -0.6445024\n",
            " -0.10949156 -0.3294202  -0.9312185   0.61979795 -0.18464996 -0.82589895\n",
            "  0.0225931  -0.29143187 -0.33856544 -0.3245003   0.09949873 -0.46184742\n",
            "  0.5087854   0.04201581 -0.13967606 -0.31455138 -0.63901407  0.10873411\n",
            "  0.01068647 -0.0264487   0.24568902 -0.36740378  0.01334102 -0.5084201\n",
            "  0.5101337   0.25338858 -0.1209445   0.13090652  0.30461925  0.25520906\n",
            "  0.19631308 -0.31499982  0.2664766   0.2559549  -0.0930006   0.04364314\n",
            "  0.43992937  0.44425172  0.23451523  0.35472086]\n",
            "------------------------------\n",
            "Similarity between film and drama: 0.64111966\n",
            "Similarity between film and tiger: 0.29915115\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oArMIJzYOmUR"
      },
      "source": [
        "#### An interesting obeseravtion if you noticed is that CBOW trains faster than SkipGram in both cases.\n",
        "We will leave it to the user to figure out why. A hint would be to refer the working of CBOW and skipgram."
      ]
    }
  ]
}