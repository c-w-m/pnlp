{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data_Augmentation_Using_NLPaug.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "pnlp37",
      "language": "python",
      "name": "pnlp37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c-w-m/pnlp/blob/master/Ch2/05_Data_Augmentation_Using_NLPaug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yavI9mt4gayF"
      },
      "source": [
        "# 05 Data Augmentation Using __NLPaug__\n",
        "This notebook demostrate the usage of a character augmenter, word augmenter. There are other types such as augmentation for sentences, audio, spectrogram inputs etc. All of the types many before mentioned types and many more can be found at the [github repo](https://github.com/makcedward/nlpaug) and [docs](https://nlpaug.readthedocs.io/en/latest/) of nlpaug."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:15:03.818048Z",
          "start_time": "2021-04-03T11:15:01.468101Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF5zJdr-kAPY",
        "outputId": "b1a5e941-bc0c-492b-9ea3-0dd2c732aad9"
      },
      "source": [
        "#Installing the nlpaug package\n",
        "!pip install nlpaug==0.0.14"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nlpaug==0.0.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/6c/ca85b6bd29926561229e8c9f677c36c65db9ef1947bfc175e6641bc82ace/nlpaug-0.0.14-py3-none-any.whl (101kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 17.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 24.0MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30kB 28.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 22.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 71kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 81kB 13.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 92kB 13.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 6.8MB/s \n",
            "\u001b[?25hInstalling collected packages: nlpaug\n",
            "Successfully installed nlpaug-0.0.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:15:11.595619Z",
          "start_time": "2021-04-03T11:15:11.593618Z"
        },
        "id": "8yhkOl3cgZ28"
      },
      "source": [
        "#this will be the base text which we will be using throughout this notebook\n",
        "text=\"The quick brown fox jumps over the lazy dog .\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:15:15.458928Z",
          "start_time": "2021-04-03T11:15:12.067195Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekFhzIWHUmoj",
        "outputId": "eb29df07-6a4f-4bad-b6aa-2d4eae8126a1"
      },
      "source": [
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nlpaug.flow as nafc\n",
        "\n",
        "from nlpaug.util import Action\n",
        "import os\n",
        "!git clone https://github.com/makcedward/nlpaug.git\n",
        "os.environ[\"MODEL_DIR\"] = 'nlpaug/model/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nlpaug'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 4564 (delta 43), reused 53 (delta 25), pack-reused 4473\u001b[K\n",
            "Receiving objects: 100% (4564/4564), 2.96 MiB | 11.70 MiB/s, done.\n",
            "Resolving deltas: 100% (3205/3205), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xo3CzNhh-zU"
      },
      "source": [
        "### Augmentation at the Character Level\n",
        "\n",
        "\n",
        "1.   OCR Augmenter: To read textual data from on image, we need an OCR(optical character recognition) model. Once the text is extracted from the image, there may be errors like; '0' instead of an 'o', '2' instead of 'z' and other such similar errors.  \n",
        "2.   Keyboard Augmenter: While typing/texting typos are fairly common this augmenter simulates the errors by substituting characters in words with ones at a similar distance on a keyboard.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:15:15.474943Z",
          "start_time": "2021-04-03T11:15:15.459929Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfAaokTmjzak",
        "outputId": "409c16a2-0faf-4481-f26e-1312f056250b"
      },
      "source": [
        "#OCR augmenter\n",
        "#import nlpaug.augmenter.char as nac\n",
        "\n",
        "aug = nac.OcrAug()  \n",
        "augmented_texts = aug.augment(text, n=3) #specifying n=3 gives us only 3 augmented versions of the sentence.\n",
        "\n",
        "print(\"Original:\")\n",
        "print(text)\n",
        "\n",
        "print(\"Augmented Texts:\")\n",
        "print(augmented_texts)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:\n",
            "The quick brown fox jumps over the lazy dog .\n",
            "Augmented Texts:\n",
            "['The quick 6rown fux jumps uver the lazy dog .', 'The quick brown fux jumps uver the lazy dog .', 'The quicr brown fox jump8 over the lazy dog .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:15:16.903143Z",
          "start_time": "2021-04-03T11:15:16.880652Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKQCpS35j9Ie",
        "outputId": "91f464e1-8f9b-480d-f6cd-1e7cec89bf36"
      },
      "source": [
        "#Keyboard Augmenter\n",
        "#import nlpaug.augmenter.word as naw\n",
        "\n",
        "\n",
        "aug = nac.KeyboardAug()\n",
        "augmented_text = aug.augment(text, n=3) #specifying n=3 gives us only 3 augmented versions of the sentence.\n",
        "\n",
        "print(\"Original:\")\n",
        "print(text)\n",
        "\n",
        "print(\"Augmented Text:\")\n",
        "print(augmented_text)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:\n",
            "The quick brown fox jumps over the lazy dog .\n",
            "Augmented Text:\n",
            "['The quick brown fox jumps Kver the laXy dog .', 'The quick brown fox jumps over the Kazy dog .', 'The quick brown fox jumps over the lAzy dog .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbfPMwZWmper"
      },
      "source": [
        "There are other types of character augmenters too. Their details are avaiable in the links mentioned at the beginning of this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MufLJXsQm4i1"
      },
      "source": [
        "### Augmentation at the Word Level\n",
        "\n",
        "Augmentation is important at the word level as well , here we use word2vec to insert or substitute a similar word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc_K1-niTGFP"
      },
      "source": [
        "**Spelling** **augmentor**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:16:58.980739Z",
          "start_time": "2021-04-03T11:16:58.532879Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qzmv4QCYrJe",
        "outputId": "5a0377a8-577d-4a30-b6e6-e1c500d8c7aa"
      },
      "source": [
        "!pip install wget\n",
        "\n",
        "#Downloading the required txt file\n",
        "import wget\n",
        "\n",
        "if not os.path.exists(\"spelling_en.txt\"):\n",
        "    wget.download(\"https://raw.githubusercontent.com/makcedward/nlpaug/5238e0be734841b69651d2043df535d78a8cc594/nlpaug/res/word/spelling/spelling_en.txt\")\n",
        "else:\n",
        "    print(\"File already exists\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=09ce74d93cb8eceba7345ac0a1a75d6f213c3f9aaea51916f6264f3850ca31e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:17:00.723918Z",
          "start_time": "2021-04-03T11:17:00.619823Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOHrgDIill2F",
        "outputId": "38aadbc0-42b9-479a-9b78-066960ff1653"
      },
      "source": [
        "#Substitute word by spelling mistake words dictionary\n",
        "aug = naw.SpellingAug('spelling_en.txt')\n",
        "augmented_texts = aug.augment(text)\n",
        "print(\"Original:\")\n",
        "print(text)\n",
        "print(\"Augmented Texts:\")\n",
        "print(augmented_texts)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:\n",
            "The quick brown fox jumps over the lazy dog .\n",
            "Augmented Texts:\n",
            "tThe quikly brown fox jumps over hte lazy dog .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaeQOtVqTQKG"
      },
      "source": [
        "**Word embeddings augmentor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:42:53.178843Z",
          "start_time": "2021-04-03T11:42:53.163829Z"
        },
        "id": "HSIKinY1nGaM",
        "outputId": "c5429c05-312d-4bbf-ca6d-6dc4065fb865",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import gzip\n",
        "import shutil\n",
        "\n",
        "gn_vec_path = \"GoogleNews-vectors-negative300.bin\"\n",
        "if not os.path.exists(\"GoogleNews-vectors-negative300.bin\"):\n",
        "    if not os.path.exists(\"../Ch3/GoogleNews-vectors-negative300.bin\"):\n",
        "        #Downloading the reqired model\n",
        "        if not os.path.exists(\"../Ch3/GoogleNews-vectors-negative300.bin.gz\"):\n",
        "            if not os.path.exists(\"GoogleNews-vectors-negative300.bin.gz\"):\n",
        "                wget.download(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\")\n",
        "            gn_vec_zip_path = \"GoogleNews-vectors-negative300.bin.gz\"\n",
        "        else:\n",
        "            gn_vec_zip_path = \"../Ch3/GoogleNews-vectors-negative300.bin.gz\"\n",
        "        #Extracting the required model\n",
        "        with gzip.open(gn_vec_zip_path, 'rb') as f_in:\n",
        "            with open(gn_vec_path, 'wb') as f_out:\n",
        "                shutil.copyfileobj(f_in, f_out)\n",
        "    else:\n",
        "        gn_vec_path = \"../Ch3/\" + gn_vec_path\n",
        "\n",
        "print(f\"Model at {gn_vec_path}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model at GoogleNews-vectors-negative300.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf_QHk-SgegN"
      },
      "source": [
        "Insert word randomly by word embeddings similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:44:12.444755Z",
          "start_time": "2021-04-03T11:43:07.255745Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffUb6s-XTOsQ",
        "outputId": "009b4be3-4a8e-4d0e-8cd7-638bc043cad0"
      },
      "source": [
        "# model_type: word2vec, glove or fasttext\n",
        "aug = naw.WordEmbsAug(\n",
        "    model_type='word2vec', model_path=gn_vec_path,\n",
        "    action=\"insert\")\n",
        "augmented_text = aug.augment(text)\n",
        "print(\"Original:\")\n",
        "print(text)\n",
        "print(\"Augmented Text:\")\n",
        "print(augmented_text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:\n",
            "The quick brown fox jumps over the lazy dog .\n",
            "Augmented Text:\n",
            "Belgian The quick BRETT brown fox jumps over Prepaid the lazy dog .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUB3Nd4Wghd0"
      },
      "source": [
        "Substitute word by word2vec similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:44:12.948639Z",
          "start_time": "2021-04-03T11:44:12.446757Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSeZNfQRfy2l",
        "outputId": "ea2d71dc-2229-47d8-a94c-7f1856df4632"
      },
      "source": [
        "aug = naw.WordEmbsAug(\n",
        "    model_type='word2vec', model_path=gn_vec_path,\n",
        "    action=\"substitute\")\n",
        "augmented_text = aug.augment(text)\n",
        "print(\"Original:\")\n",
        "print(text)\n",
        "print(\"Augmented Text:\")\n",
        "print(augmented_text)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:\n",
            "The quick brown fox jumps over the lazy dog .\n",
            "Augmented Text:\n",
            "Similarly Barring_miraculous brown fox jumps over the lazy bull_terrier .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reALNlOuDI9u"
      },
      "source": [
        "There are many more features which nlpaug offers you can visit the github repo and documentation for further details"
      ]
    }
  ]
}